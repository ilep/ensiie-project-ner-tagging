{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de mots pour des annonces immobilières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le but de ce projet est de récuperer les informations importantes d'une annonce immobilière grâce à un classifieur de mots pour des annonces immobilières.\n",
    "\n",
    "Les informations à récupérer sont : \n",
    "+ M2: surface en m2\n",
    "+ N_PIECES : nombre de pièces\n",
    "+ N_CHAMBRES: nombre de chambres\n",
    "+ VILLE:\n",
    "+ QUARTIER: nom du quartier\n",
    "+ ADRESSE: nom du la rue (avec le numero si indiqué)\n",
    "+ TRANSPORTS_PROXIMITE: transports à proximité\n",
    "+ ANNEE_CONSTRUCTION: annee de construction de l'immeuble\n",
    "+ CODE_POSTAL: code postal (92130)\n",
    "+ LOYER_CC: montant du loyer charges comprises\n",
    "+ LOYER_HC: montant du loyer hors charges\n",
    "+ CHARGES_LOCATAIRE_MOIS: montant des charges mensuelles\n",
    "+ DEPOT_GARANTIE: montant du depot de garantie\n",
    "+ N_ETAGE:numero etage\n",
    "+ AVEC_ASCENSEUR:\n",
    "+ DATE_DISPO:\n",
    "+ TYPE_CHAUFFAGE: individuel /collectif\n",
    "+ TYPE_LOCATION: meublé ou non meublé\n",
    "+ PARKING :\n",
    "+ EXTERIEUR : présence d'un jardin/balcon/terrasse\n",
    "+ COPROPRIETE :\n",
    "+ HONORAIRE : montant des honoraires de l'agence\n",
    "+ STOCKAGE : présence d'une cave/box ou autre élément de stockage\n",
    "\n",
    "Pour cela nous allons utiliser le NER tagging et des techniques features-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "* I/ Importation de la base de données\n",
    "* II/ Création des features\n",
    "* III/ Classification avec le modele CRF \n",
    "    + A/ Creation base de donnée pour CRF\n",
    "    + B/ Apprentissage et Validation du modele CRF\n",
    "        + 1/ Apprentissage et Validation simple du modele CRF\n",
    "        + 2/ Apprentissage après optimisation des hyperparametres et k-cross Validation sur le train et validation du modele CRF sur le test\n",
    "* IV/ Interpretation avec le modele CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabi0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize \n",
    "import unicodedata\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from collections import Counter\n",
    "import eli5\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Importation de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ad_to_dataframe(line, nb_line):\n",
    "    \"\"\"Fonction qui à partir d'une ligne d'un fichier Json de créer une dataframe à \n",
    "    trois colonnes. La première colonne correspond au numéro de l'annonce, la seconde \n",
    "    contient les mots de l'annonce et la troisième les positions du mot dans l'annonce.\"\"\" \n",
    "    Vect_word=(word_tokenize(eval(line.strip().replace('\\xa0',' '))[\"text\"])) # Tokenisation\n",
    "    nb_sent_list=list(map(int, nb_line*np.ones(len(Vect_word)))) # Numéro annonce\n",
    "    # Position\n",
    "    offset = 0                                                                  \n",
    "    list_pos=list()\n",
    "    for token in Vect_word:\n",
    "        offset = eval(line.strip().replace('\\xa0',' '))[\"text\"].find(token, offset)\n",
    "        list_pos.append([offset, offset+len(token)])\n",
    "        offset += len(token)\n",
    "    # Creation de la dataframe\n",
    "    data={'Ad#':nb_sent_list,'Words':Vect_word,'Pos':list_pos}\n",
    "    df=pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Fonction qui permet de corriger les annotations qui surlignent un espace blanc au début \n",
    "    ou à la fin de l'annotations sous Doccano\"\"\"\n",
    "    if text[0]==' ':      \n",
    "        if text[-1]==' ':\n",
    "            return 3\n",
    "        return 1\n",
    "    elif text[-1]==' ':\n",
    "        return 2\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def from_line_to_list_label(line):\n",
    "    \"\"\"Fonction qui permet de sortir les informations des labels (text, label et positions)\n",
    "    à partir d'une ligne du fichier json\"\"\"\n",
    "    list_word_label=list()\n",
    "    for i in range(len(eval(line)[\"labels\"])):\n",
    "        start=eval(line)[\"labels\"][i][0]  # position de depart\n",
    "        end=eval(line)[\"labels\"][i][1]    # position d'arrivee\n",
    "        label=eval(line)[\"labels\"][i][2]  # label\n",
    "        # Distinction des cas au fonction de la fonction clean_text\n",
    "        # on supprime les \\xa0 de nos annonces \n",
    "        if (clean_text(eval(line.strip().replace('\\xa0',' '))[\"text\"][start:end])==0):\n",
    "            list_word_label.append([eval(line.strip().replace('\\xa0',' '))[\"text\"][start:end],label,start,end])\n",
    "        elif (clean_text(eval(line.strip().replace('\\xa0',' '))[\"text\"][start:end])==1):\n",
    "            list_word_label.append([eval(line.strip().replace('\\xa0',' '))[\"text\"][(start+1):end],label,start+1,end])\n",
    "        elif (clean_text(eval(line.strip().replace('\\xa0',' '))[\"text\"][start:end])==2):\n",
    "            list_word_label.append([eval(line.strip().replace('\\xa0',' '))[\"text\"][start:(end-1)],label,start,end-1])\n",
    "        else:\n",
    "            list_word_label.append([eval(line.strip().replace('\\xa0',' '))[\"text\"][(start+1):(end-1)],label,start+1,end-1])\n",
    "    return list_word_label\n",
    "\n",
    "def column_tag(vect_word,list_word_pos_label):\n",
    "    \"\"\"Creation de la colonne contenant les labels pour chaque mot d'une annonce avec la convention Inside–outside–beginning tagging\"\"\"\n",
    "    list_tag=[\"O\"]*len(vect_word[\"Pos\"])\n",
    "    for i in range(len(vect_word[\"Pos\"])):\n",
    "        for elmt in list_word_pos_label:\n",
    "            if vect_word[\"Pos\"][i][0]==elmt[2] and vect_word[\"Pos\"][i][1]<=elmt[3]:\n",
    "                list_tag[i]=\"B-\"+elmt[1]\n",
    "            elif vect_word[\"Pos\"][i][0]>elmt[2] and vect_word[\"Pos\"][i][1]<=elmt[3]:\n",
    "                list_tag[i]=\"I-\"+elmt[1]\n",
    "    return list_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et creation de la base de données à partir des fichiers Json1 de Doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1 # Numéro annonce\n",
    "for i in range(1,6): # 5 fichier Json\n",
    "    with open('data/doccano/bdd'+str(i)+'.json1', encoding=\"utf-8\") as fp: #ouverture fichier\n",
    "        line = fp.readline() # lecture de la ligne\n",
    "        # Modification de la dataframe\n",
    "        if i==1: # Creation initiale de la dataframe \n",
    "            df=from_ad_to_dataframe(line.replace('null','\"null\"'),cnt)\n",
    "            list_word_pos_label=from_line_to_list_label(line.replace('null','\"null\"'))\n",
    "            list_tag=column_tag(df,list_word_pos_label)\n",
    "            df[\"Tag\"]=list_tag\n",
    "        else :\n",
    "            df_ad=from_ad_to_dataframe(line.replace('null','\"null\"'),cnt)\n",
    "            list_word_pos_label=from_line_to_list_label(line.replace('null','\"null\"'))\n",
    "            list_tag=column_tag(df_ad,list_word_pos_label)\n",
    "            df_ad[\"Tag\"]=list_tag\n",
    "            df=df.append(df_ad, ignore_index = True)\n",
    "        while line: # pour toutes les lignes\n",
    "            if cnt!=1:\n",
    "                df_ad=from_ad_to_dataframe(line.replace('null','\"null\"'),cnt)\n",
    "                list_word_pos_label=from_line_to_list_label(line.replace('null','\"null\"'))\n",
    "                list_tag=column_tag(df_ad,list_word_pos_label)\n",
    "                df_ad[\"Tag\"]=list_tag\n",
    "                df=df.append(df_ad, ignore_index = True)\n",
    "            line = fp.readline()\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad#</th>\n",
       "      <th>Words</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41057</th>\n",
       "      <td>482</td>\n",
       "      <td>24</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>B-ADRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41058</th>\n",
       "      <td>482</td>\n",
       "      <td>rue</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41059</th>\n",
       "      <td>482</td>\n",
       "      <td>du</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41060</th>\n",
       "      <td>482</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>[10, 19]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41061</th>\n",
       "      <td>482</td>\n",
       "      <td>Ferber-</td>\n",
       "      <td>[20, 27]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41174</th>\n",
       "      <td>482</td>\n",
       "      <td>d'honoraires</td>\n",
       "      <td>[612, 624]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41175</th>\n",
       "      <td>482</td>\n",
       "      <td>d'état</td>\n",
       "      <td>[625, 631]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41176</th>\n",
       "      <td>482</td>\n",
       "      <td>des</td>\n",
       "      <td>[632, 635]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41177</th>\n",
       "      <td>482</td>\n",
       "      <td>lieux</td>\n",
       "      <td>[636, 641]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41178</th>\n",
       "      <td>482</td>\n",
       "      <td>.</td>\n",
       "      <td>[641, 642]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ad#         Words         Pos        Tag\n",
       "41057  482            24      [0, 2]  B-ADRESSE\n",
       "41058  482           rue      [3, 6]  I-ADRESSE\n",
       "41059  482            du      [7, 9]  I-ADRESSE\n",
       "41060  482     Capitaine    [10, 19]  I-ADRESSE\n",
       "41061  482       Ferber-    [20, 27]          O\n",
       "...    ...           ...         ...        ...\n",
       "41174  482  d'honoraires  [612, 624]          O\n",
       "41175  482        d'état  [625, 631]          O\n",
       "41176  482           des  [632, 635]          O\n",
       "41177  482         lieux  [636, 641]          O\n",
       "41178  482             .  [641, 642]          O\n",
       "\n",
       "[122 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Ad#']==482,:] # On affiche une partie de la dataframe pour l'annonce 482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce niveau la dataframe contient donc une colonne qui indique le numéro de l'annonce, une colonne avec les mots, une colonne pour les postions du mots dans l'annonce et le label/tag avec les convientions IOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Creation des features\n",
    "\n",
    "Nous allons créer les features suivantes : \n",
    "+ le mot contient 4 caractères ou moins \n",
    "+ le mot est un nombre\n",
    "+ le mot commence par une lettre majuscule \n",
    "+ le mot est en majuscule\n",
    "+ le mot contient un symbole \n",
    "+ le mot contient des chiffres et des lettres \n",
    "+ le mot contient un mot clé (nous avons une liste de mots clés que nous avons choisi judicieusement)\n",
    "+ le mot precedent et reconnaitre si c'est un mot clé\n",
    "+ le mot precedent le mot precedent et reconnaitre si c'est un mot clé\n",
    "+ le mot suivant et reconnaitre si c'est un mot clé\n",
    "+ le mot suivant le mot suivant et reconnaitre si c'est un mot clé\n",
    "\n",
    "### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature mot court\n",
    "def is_small_word(Vect_word):\n",
    "    list_small=list()\n",
    "    for word in Vect_word:      \n",
    "        if(len(word)<=4):\n",
    "            list_small.append(1)\n",
    "        else:\n",
    "            list_small.append(0)\n",
    "    return list_small\n",
    "\n",
    "# Feature le mot est un nombre (decimal ou non)\n",
    "def is_number(Vect_word):\n",
    "    list_number=list()\n",
    "    for word in Vect_word:      \n",
    "        word=word.replace(\",\",\"\").replace(\".\",\"\") # on peut ecrire un nombre decimal avec un point ou une virgule\n",
    "        try:\n",
    "            float(word)\n",
    "            list_number.append(1)\n",
    "        except ValueError:\n",
    "            list_number.append(0)\n",
    "    return list_number\n",
    "\n",
    "# Feature premiere lettre en majuscule\n",
    "def is_first_letter_upper(Vect_word):\n",
    "    list_upper=list()\n",
    "    for word in Vect_word:\n",
    "        list_upper.append(int(word[0].isupper()))\n",
    "    return list_upper\n",
    "\n",
    "# Feature mot en majuscule\n",
    "def is_all_upper(Vect_word):\n",
    "    list_upper=list()\n",
    "    for word in Vect_word:\n",
    "        list_upper.append(int(word.isupper()))\n",
    "    return list_upper\n",
    "\n",
    "# Feature symbole dans le mot\n",
    "def symbole_in_word(Vect_word):\n",
    "    list_symbole=list()\n",
    "    for word in Vect_word:\n",
    "        list_symbole.append( int( not( word.isalpha() or word.isnumeric() ) ) ) # pas un chiffre, pas une lettre donc un symbole\n",
    "    return list_symbole\n",
    "\n",
    "#Feature nombre et lettre dans le mot\n",
    "def is_number_and_letter(Vect_word):\n",
    "    list_number_and_letter = list()\n",
    "    for word in Vect_word:\n",
    "        numeric = 0\n",
    "        alpha = 0\n",
    "        for c in word:\n",
    "            if c.isnumeric():\n",
    "                numeric=1\n",
    "            if c.isalpha():\n",
    "                alpha=1\n",
    "        list_number_and_letter.append(alpha*numeric)\n",
    "    return(list_number_and_letter)\n",
    "\n",
    "#Feature mot clé\n",
    "\n",
    "def strip_accents(text):\n",
    "    \"\"\"Fonction qui retire les accents du texte\"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return text\n",
    "\n",
    "def is_key_word(Vect_word):\n",
    "    keywords = [\"chambres\",\"pieces\",\"m2\",\"m\",\"loyer\",\"cc\",\"hc\",\"rue\",\"avenue\",\"quartier\",\"euro\",\"eur\",\"etage\",\"€\",\"individuel\",\"collectif\",\n",
    "                \"meuble\",\"jardin\",\"balcon\",\"terasse\",\"stationnement\",\"parking\",\"cave\",\"box\",\"immediatement\",\"suite\"]\n",
    "    list_keyword = list()\n",
    "    for word in Vect_word:\n",
    "        test = 0\n",
    "        #remove all accents\n",
    "        s = strip_accents(word)\n",
    "        #put it in lower case\n",
    "        s = s.lower()\n",
    "        #use sequencematcher\n",
    "        for key in keywords:\n",
    "            if(SequenceMatcher(None,s,key).ratio() > 0.7): # 0.7 est le threshold\n",
    "                test = 1\n",
    "                break\n",
    "        list_keyword.append(test)\n",
    "    return(list_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On complete la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df[\"is_small_word\"]=is_small_word(df['Words'])\n",
    "df[\"is_number\"]=is_number(df['Words'])\n",
    "df[\"is_first_letter_upper\"]=is_first_letter_upper(df['Words'])\n",
    "df[\"is_all_upper\"]=is_all_upper(df['Words'])\n",
    "df[\"symbole_in_word\"]=symbole_in_word(df['Words'])\n",
    "df[\"is_number_and_letter\"]=is_number_and_letter(df['Words'])\n",
    "df[\"is_key_word\"]=is_key_word(df['Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad#</th>\n",
       "      <th>Words</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Tag</th>\n",
       "      <th>is_small_word</th>\n",
       "      <th>is_number</th>\n",
       "      <th>is_first_letter_upper</th>\n",
       "      <th>is_all_upper</th>\n",
       "      <th>symbole_in_word</th>\n",
       "      <th>is_number_and_letter</th>\n",
       "      <th>is_key_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41057</th>\n",
       "      <td>482</td>\n",
       "      <td>24</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>B-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41058</th>\n",
       "      <td>482</td>\n",
       "      <td>rue</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41059</th>\n",
       "      <td>482</td>\n",
       "      <td>du</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41060</th>\n",
       "      <td>482</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>[10, 19]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41061</th>\n",
       "      <td>482</td>\n",
       "      <td>Ferber-</td>\n",
       "      <td>[20, 27]</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ad#      Words       Pos        Tag  is_small_word  is_number  \\\n",
       "41057  482         24    [0, 2]  B-ADRESSE              1          1   \n",
       "41058  482        rue    [3, 6]  I-ADRESSE              1          0   \n",
       "41059  482         du    [7, 9]  I-ADRESSE              1          0   \n",
       "41060  482  Capitaine  [10, 19]  I-ADRESSE              0          0   \n",
       "41061  482    Ferber-  [20, 27]          O              0          0   \n",
       "\n",
       "       is_first_letter_upper  is_all_upper  symbole_in_word  \\\n",
       "41057                      0             0                0   \n",
       "41058                      0             0                0   \n",
       "41059                      0             0                0   \n",
       "41060                      1             0                0   \n",
       "41061                      1             0                1   \n",
       "\n",
       "       is_number_and_letter  is_key_word  \n",
       "41057                     0            0  \n",
       "41058                     0            1  \n",
       "41059                     0            0  \n",
       "41060                     0            0  \n",
       "41061                     0            0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Ad#']==482,:].head() # On affiche une partie de la dataframe pour l'annonce 482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features mots precedents, mots suivants, et reconnaitre si ce sont des mots clés\n",
    "Number_ad=df['Ad#'].iloc[-1]\n",
    "\n",
    "list_prev_word=list()\n",
    "list_2prev_word=list()\n",
    "list_next_word=list()\n",
    "list_2next_word=list()\n",
    "\n",
    "list_prev_key=list()\n",
    "list_2prev_key=list()\n",
    "list_next_key=list()\n",
    "list_2next_key=list()\n",
    "\n",
    "for i in range(Number_ad):\n",
    "    Vect_ad_word=df.loc[df['Ad#']==i+1,:][\"Words\"]\n",
    "    Vect_ad_key=df.loc[df['Ad#']==i+1,:][\"is_key_word\"]\n",
    "    for j in range(len(Vect_ad_word)):\n",
    "        # Pour chaque annonce, on fait attention aux deux premiers et deux derniers mots  \n",
    "        if j==0:\n",
    "            list_prev_word.append(\"__Start1__\")\n",
    "            list_2prev_word.append(\"__Start2__\")\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(0)\n",
    "            list_2prev_key.append(0)\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])\n",
    "            \n",
    "        elif j==1:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(\"__Start1__\")\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(0)\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])\n",
    "        \n",
    "        elif j==len(Vect_ad_word)-2:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(\"__End1__\")\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(0)\n",
    "        \n",
    "        elif j==len(Vect_ad_word)-1:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(\"__End1__\")\n",
    "            list_2next_word.append(\"__End2__\")\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(0)\n",
    "            list_2next_key.append(0)\n",
    "        else :\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On complete la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"2prev_word\"]=list_2prev_word\n",
    "df[\"2prev_key\"]=list_2prev_key\n",
    "\n",
    "df[\"prev_word\"]=list_prev_word\n",
    "df[\"prev_key\"]=list_prev_key\n",
    "\n",
    "df[\"next_word\"]=list_next_word\n",
    "df[\"next_key\"]=list_next_key\n",
    "\n",
    "df[\"2next_word\"]=list_2next_word\n",
    "df[\"2next_key\"]=list_2next_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad#</th>\n",
       "      <th>Words</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Tag</th>\n",
       "      <th>is_small_word</th>\n",
       "      <th>is_number</th>\n",
       "      <th>is_first_letter_upper</th>\n",
       "      <th>is_all_upper</th>\n",
       "      <th>symbole_in_word</th>\n",
       "      <th>is_number_and_letter</th>\n",
       "      <th>is_key_word</th>\n",
       "      <th>2prev_word</th>\n",
       "      <th>2prev_key</th>\n",
       "      <th>prev_word</th>\n",
       "      <th>prev_key</th>\n",
       "      <th>next_word</th>\n",
       "      <th>next_key</th>\n",
       "      <th>2next_word</th>\n",
       "      <th>2next_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41057</th>\n",
       "      <td>482</td>\n",
       "      <td>24</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>B-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__Start2__</td>\n",
       "      <td>0</td>\n",
       "      <td>__Start1__</td>\n",
       "      <td>0</td>\n",
       "      <td>rue</td>\n",
       "      <td>1</td>\n",
       "      <td>du</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41058</th>\n",
       "      <td>482</td>\n",
       "      <td>rue</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>__Start1__</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>du</td>\n",
       "      <td>0</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41059</th>\n",
       "      <td>482</td>\n",
       "      <td>du</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>rue</td>\n",
       "      <td>1</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferber-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41060</th>\n",
       "      <td>482</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>[10, 19]</td>\n",
       "      <td>I-ADRESSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rue</td>\n",
       "      <td>1</td>\n",
       "      <td>du</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferber-</td>\n",
       "      <td>0</td>\n",
       "      <td>Copropriété</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41061</th>\n",
       "      <td>482</td>\n",
       "      <td>Ferber-</td>\n",
       "      <td>[20, 27]</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>du</td>\n",
       "      <td>0</td>\n",
       "      <td>Capitaine</td>\n",
       "      <td>0</td>\n",
       "      <td>Copropriété</td>\n",
       "      <td>0</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ad#      Words       Pos        Tag  is_small_word  is_number  \\\n",
       "41057  482         24    [0, 2]  B-ADRESSE              1          1   \n",
       "41058  482        rue    [3, 6]  I-ADRESSE              1          0   \n",
       "41059  482         du    [7, 9]  I-ADRESSE              1          0   \n",
       "41060  482  Capitaine  [10, 19]  I-ADRESSE              0          0   \n",
       "41061  482    Ferber-  [20, 27]          O              0          0   \n",
       "\n",
       "       is_first_letter_upper  is_all_upper  symbole_in_word  \\\n",
       "41057                      0             0                0   \n",
       "41058                      0             0                0   \n",
       "41059                      0             0                0   \n",
       "41060                      1             0                0   \n",
       "41061                      1             0                1   \n",
       "\n",
       "       is_number_and_letter  is_key_word  2prev_word  2prev_key   prev_word  \\\n",
       "41057                     0            0  __Start2__          0  __Start1__   \n",
       "41058                     0            1  __Start1__          0          24   \n",
       "41059                     0            0          24          0         rue   \n",
       "41060                     0            0         rue          1          du   \n",
       "41061                     0            0          du          0   Capitaine   \n",
       "\n",
       "       prev_key    next_word  next_key   2next_word  2next_key  \n",
       "41057         0          rue         1           du          0  \n",
       "41058         0           du         0    Capitaine          0  \n",
       "41059         1    Capitaine         0      Ferber-          0  \n",
       "41060         0      Ferber-         0  Copropriété          0  \n",
       "41061         0  Copropriété         0           de          0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Ad#']==482,:].head() # On regarde les features de l'annonce 482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ad#                      0\n",
       "Words                    0\n",
       "Pos                      0\n",
       "Tag                      0\n",
       "is_small_word            0\n",
       "is_number                0\n",
       "is_first_letter_upper    0\n",
       "is_all_upper             0\n",
       "symbole_in_word          0\n",
       "is_number_and_letter     0\n",
       "is_key_word              0\n",
       "2prev_word               0\n",
       "2prev_key                0\n",
       "prev_word                0\n",
       "prev_key                 0\n",
       "next_word                0\n",
       "next_key                 0\n",
       "2next_word               0\n",
       "2next_key                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # On verifie qu'il n'y a pas de NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Classification avec le modele CRF\n",
    "\n",
    "Pour utiliser le modele CRF, on doit modifier notre base de donnée et créer des dictionnaire pour pouvoir mettre notre dataframe en entrée du modele\n",
    "\n",
    "### A/ Creation base de donnée pour CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque mot on crée un dictionaire à partir de la dataframe existante\n",
    "def word2features(df_one_ad, i):\n",
    "    df_one_word = df_one_ad.iloc[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': df_one_word[\"Words\"].lower(),\n",
    "        'is_small_word': bool(df_one_word[\"is_small_word\"]),\n",
    "        'is_number': bool(df_one_word[\"is_number\"]),\n",
    "        'is_first_letter_upper': bool(df_one_word[\"is_first_letter_upper\"]),\n",
    "        'is_all_upper': bool(df_one_word[\"is_all_upper\"]),\n",
    "        'symbole_in_word': bool(df_one_word[\"symbole_in_word\"]),      \n",
    "        'is_number_and_letter': bool(df_one_word[\"is_number_and_letter\"]),\n",
    "        'is_key_word': bool(df_one_word[\"is_key_word\"]),\n",
    "        '2prev_word': df_one_word[\"2prev_word\"].lower(),\n",
    "        '2prev_key': bool(df_one_word[\"2prev_key\"]),\n",
    "        'prev_word': df_one_word[\"prev_word\"].lower(),\n",
    "        'prev_key': bool(df_one_word[\"prev_key\"]), \n",
    "        'next_word': df_one_word[\"next_word\"].lower(),\n",
    "        'next_key': bool(df_one_word[\"next_key\"]), \n",
    "        '2next_word': df_one_word[\"2next_word\"].lower(),\n",
    "        '2next_key': bool(df_one_word[\"2next_key\"]), \n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Vecteur contenant les dictionnaires d'une annonce \n",
    "def ad2features(df_one_ad):\n",
    "    return [word2features(df_one_ad, i) for i in range(len(df_one_ad))]\n",
    "\n",
    "# Return le tag d'un mot\n",
    "def word2tags(df_one_ad, i):\n",
    "    return df_one_ad.iloc[i][\"Tag\"]\n",
    "\n",
    "# Vecteur de tags d'une annonce\n",
    "def ad2tags(df_one_ad):\n",
    "    return [word2tags(df_one_ad, i) for i in range(len(df_one_ad))]\n",
    "\n",
    "Number_ad=df['Ad#'].iloc[-1]\n",
    "\n",
    "# Base de données pour CRF\n",
    "X_crf=list() \n",
    "y_crf=list() # Target \n",
    "for i in range(Number_ad):\n",
    "    X_crf.append(ad2features(df.loc[df['Ad#']==i+1,:]))\n",
    "    y_crf.append(ad2tags(df.loc[df['Ad#']==i+1,:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'situé',\n",
       "  'is_small_word': False,\n",
       "  'is_number': False,\n",
       "  'is_first_letter_upper': True,\n",
       "  'is_all_upper': False,\n",
       "  'symbole_in_word': False,\n",
       "  'is_number_and_letter': False,\n",
       "  'is_key_word': True,\n",
       "  '2prev_word': '__start2__',\n",
       "  '2prev_key': False,\n",
       "  'prev_word': '__start1__',\n",
       "  'prev_key': False,\n",
       "  'next_word': 'à',\n",
       "  'next_key': False,\n",
       "  '2next_word': '6',\n",
       "  '2next_key': False},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'à',\n",
       "  'is_small_word': True,\n",
       "  'is_number': False,\n",
       "  'is_first_letter_upper': False,\n",
       "  'is_all_upper': False,\n",
       "  'symbole_in_word': False,\n",
       "  'is_number_and_letter': False,\n",
       "  'is_key_word': False,\n",
       "  '2prev_word': '__start1__',\n",
       "  '2prev_key': False,\n",
       "  'prev_word': 'situé',\n",
       "  'prev_key': True,\n",
       "  'next_word': '6',\n",
       "  'next_key': False,\n",
       "  '2next_word': 'stations',\n",
       "  '2next_key': False}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_crf[0][0:2] # On observe la base de donnée CRF pour les deux premiers mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_crf[0][0:2] # On observe la base de donnée CRF pour les deux premiers mots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B/ Apprentissage et Validation du modele CRF\n",
    "\n",
    "Creation de la base de train et de test (proportion 2/3, 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crf_train, X_crf_test, y_crf_train, y_crf_test = train_test_split(X_crf,y_crf,test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1/ Apprentissage et Validation simple du modele CRF\n",
    "\n",
    "On entraine le modele avec la base de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_crf_train, y_crf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADRESSE',\n",
       " 'I-ADRESSE',\n",
       " 'B-N_ETAGE',\n",
       " 'B-AVEC_ASCENSEUR',\n",
       " 'I-AVEC_ASCENSEUR',\n",
       " 'B-N_PIECES',\n",
       " 'B-N_CHAMBRES',\n",
       " 'B-STOCKAGE',\n",
       " 'B-PARKING',\n",
       " 'B-DATE_DISPO',\n",
       " 'I-VILLE',\n",
       " 'B-TRANSPORTS_PROXIMITE',\n",
       " 'I-TRANSPORTS_PROXIMITE',\n",
       " 'B-TYPE_CHAUFFAGE',\n",
       " 'B-M2',\n",
       " 'B-EXTERIEUR',\n",
       " 'B-QUARTIER',\n",
       " 'B-VILLE',\n",
       " 'B-LOYER_CC',\n",
       " 'I-DATE_DISPO',\n",
       " 'B-HONORAIRE',\n",
       " 'I-QUARTIER',\n",
       " 'I-N_PIECES',\n",
       " 'B-TYPE_LOCATION',\n",
       " 'B-ANNEE_CONSTRUCTION',\n",
       " 'B-LOYER_HC',\n",
       " 'B-CHARGES_LOCATAIRE_MOIS',\n",
       " 'B-DEPOT_GARANTIE',\n",
       " 'I-N_ETAGE',\n",
       " 'I-LOYER_HC',\n",
       " 'I-ANNEE_CONSTRUCTION',\n",
       " 'I-DEPOT_GARANTIE',\n",
       " 'B-COPROPRIETE',\n",
       " 'I-HONORAIRE',\n",
       " 'B-CODE_POSTAL',\n",
       " 'I-LOYER_CC',\n",
       " 'I-M2',\n",
       " 'I-TYPE_CHAUFFAGE',\n",
       " 'I-TYPE_LOCATION',\n",
       " 'I-COPROPRIETE',\n",
       " 'I-STOCKAGE',\n",
       " 'I-PARKING',\n",
       " 'I-CHARGES_LOCATAIRE_MOIS']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On affiche les différents modeles que l'on doit recuperer\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On predit les classes sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabi0\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\gabi0\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8412282068598782"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_crf_test)\n",
    "metrics.flat_f1_score(y_crf_test, y_pred, \n",
    "                      average='weighted', labels=labels)\n",
    "\n",
    "# WARNING EXPLANATION some labels in y_true don't appear in y_pred\n",
    "# This means that there is no F-score to calculate for this label, and thus the F-score for this case is considered to be 0.0. Since you requested an average of the score, you must take into account that a score of 0 was included in the calculation, and this is why scikit-learn is showing you that warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe une accuracy proche de 85%, ce qui pas mal vu le nombre de classes à predire. \n",
    "\n",
    "Nous allons calculer la precision, le recall et le f1-score pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabi0\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\gabi0\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "               B-ADRESSE      0.957     0.800     0.871        55\n",
      "               I-ADRESSE      0.919     0.771     0.839       118\n",
      "    B-ANNEE_CONSTRUCTION      0.950     0.679     0.792        28\n",
      "    I-ANNEE_CONSTRUCTION      1.000     0.600     0.750         5\n",
      "        B-AVEC_ASCENSEUR      0.754     0.776     0.765        67\n",
      "        I-AVEC_ASCENSEUR      0.767     0.868     0.814        53\n",
      "B-CHARGES_LOCATAIRE_MOIS      0.895     0.919     0.907        37\n",
      "I-CHARGES_LOCATAIRE_MOIS      0.000     0.000     0.000         0\n",
      "           B-CODE_POSTAL      0.833     0.833     0.833         6\n",
      "           B-COPROPRIETE      0.850     1.000     0.919        17\n",
      "           I-COPROPRIETE      0.000     0.000     0.000         0\n",
      "            B-DATE_DISPO      0.816     0.705     0.756        44\n",
      "            I-DATE_DISPO      0.903     0.651     0.757        43\n",
      "        B-DEPOT_GARANTIE      1.000     0.955     0.977        22\n",
      "        I-DEPOT_GARANTIE      1.000     1.000     1.000         3\n",
      "             B-EXTERIEUR      0.878     0.935     0.906       108\n",
      "             B-HONORAIRE      0.880     0.853     0.866        95\n",
      "             I-HONORAIRE      0.000     0.000     0.000         2\n",
      "              B-LOYER_CC      0.824     0.667     0.737        21\n",
      "              I-LOYER_CC      0.500     1.000     0.667         2\n",
      "              B-LOYER_HC      0.826     0.792     0.809        24\n",
      "              I-LOYER_HC      0.000     0.000     0.000         2\n",
      "                    B-M2      0.968     0.950     0.959       159\n",
      "                    I-M2      0.000     0.000     0.000         0\n",
      "            B-N_CHAMBRES      0.906     0.928     0.917       125\n",
      "               B-N_ETAGE      0.982     0.892     0.934       120\n",
      "               I-N_ETAGE      0.000     0.000     0.000         2\n",
      "              B-N_PIECES      0.921     0.955     0.938       134\n",
      "              I-N_PIECES      0.000     0.000     0.000         0\n",
      "               B-PARKING      0.976     0.952     0.964        84\n",
      "               I-PARKING      0.000     0.000     0.000         0\n",
      "              B-QUARTIER      0.607     0.309     0.410        55\n",
      "              I-QUARTIER      0.632     0.185     0.286        65\n",
      "              B-STOCKAGE      0.915     0.915     0.915        71\n",
      "              I-STOCKAGE      0.000     0.000     0.000         0\n",
      "  B-TRANSPORTS_PROXIMITE      0.903     0.897     0.900       146\n",
      "  I-TRANSPORTS_PROXIMITE      0.800     0.744     0.771        86\n",
      "        B-TYPE_CHAUFFAGE      0.974     0.938     0.956        81\n",
      "        I-TYPE_CHAUFFAGE      0.000     0.000     0.000         0\n",
      "         B-TYPE_LOCATION      0.689     0.721     0.705        43\n",
      "         I-TYPE_LOCATION      1.000     1.000     1.000         1\n",
      "                 B-VILLE      0.802     0.707     0.751        92\n",
      "                 I-VILLE      0.875     0.824     0.848        51\n",
      "\n",
      "               micro avg      0.886     0.821     0.852      2067\n",
      "               macro avg      0.663     0.621     0.633      2067\n",
      "            weighted avg      0.876     0.821     0.841      2067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_crf_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tout les F1_score inferieur à 0.75 et un support superieur à 10, nous allons regarder la matrice de confusion pour éventuellement trouver des features à rajouter. \n",
    "\n",
    "Nous allons regarder B-LOYER-CC (l18), B-QUARTIER (l31), I-QUARTIER (l32) et B-TYPE_LOCATION (l39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 14  0  4  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 17  2  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  3 12  0  0  0  0  0  0  0  0  1  0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 31  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "flat_list_y_test = [item for sublist in y_crf_test for item in sublist]\n",
    "flat_list_y_pred= [item for sublist in y_pred for item in sublist]\n",
    "conf_mat=confusion_matrix(flat_list_y_test, flat_list_y_pred, labels=sorted_labels)\n",
    "print(conf_mat[18])\n",
    "print(conf_mat[31])\n",
    "print(conf_mat[32])\n",
    "print(conf_mat[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreur en prevoyant 'O'  307\n",
      "Nombre d'erreur en prevoyant un autre label que 'O'  63\n"
     ]
    }
   ],
   "source": [
    "nb_good_pred=0\n",
    "sum_line=0\n",
    "for i in range(len(conf_mat)):\n",
    "    nb_good_pred+=conf_mat[i,i]\n",
    "    sum_line+=sum(conf_mat[i])\n",
    "print(\"Nombre d'erreur en prevoyant 'O' \",2067-sum_line)\n",
    "print(\"Nombre d'erreur en prevoyant un autre label que 'O' \",sum_line-nb_good_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque le tag est mauvais c'est souvent dû au fait qu'on predit un label 'O' (ce n'est pas indiqué sur la matrice de confusion mais pour calculer le nombre de mauvaises prédictions en 'O', on a juste à faire support - somme element sur la ligne). Nous avons deja des features mots cles, il est difficile de trouver encore d'autres features pour differencier 'O' et les 'vrais' tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2/ Apprentissage après optimisation des hyperparametres et k-cross Validation sur le train et validation du modele CRF sur le test\n",
    "\n",
    "##### Optimisation Hyperparametres\n",
    "\n",
    "ATTENTION : Le prochain chunk met du temps à s'executer\n",
    "\n",
    "On utilise la fonction RandomizedSearchCV pour optimiser les hyperparametres. \n",
    "Remarque : en argument de cette fonction, on peut mettre en entrée le nombre k, utilisé pour le k-cross Validation.\n",
    "Nous avons choisi k=3, on pourrait mettre un plus grand nombre mais vu le temps elevé pour l'execution du code, on se contente de k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=50, \n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_crf_train, y_crf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rs.best_estimator_)\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation sur le test avec les meilleurs paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_crf_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_crf_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont similaires même apres l'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV/ Interpretation avec le modele CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les transitions possibles entre les labels (plus le nombre est grand plus la possibilité de transition entre ces deux labels est grande)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu de la convention IOB qu'on suit, les resultats sont coherents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les features les plus communs et les moins communs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les poids des transition et les top features pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " eli5.show_weights(crf, top=10) # Currently ELI5 allows to explain weights and predictions of scikit-learn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[df['Ad#']==482,:]['Words']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui regroupe les occurences d'un label si les mots se suivent\n",
    "def occ_labels(labels):\n",
    "    i = 0\n",
    "    x = list()\n",
    "    j = 1\n",
    "    while i<len(labels):\n",
    "        tmp = i\n",
    "        while j<len(labels) and labels[tmp][2]==labels[j][2] and labels[tmp][1]==labels[j][0]-1:\n",
    "            tmp+=1\n",
    "            j+=1\n",
    "        x.append([labels[i][0],labels[j-1][1],labels[i][2]])\n",
    "        i=j\n",
    "        j=i+1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 19, 'ADRESSE'],\n",
       " [28, 39, 'COPROPRIETE'],\n",
       " [43, 47, 'ANNEE_CONSTRUCTION'],\n",
       " [64, 69, 'N_ETAGE'],\n",
       " [92, 93, 'N_PIECES'],\n",
       " [104, 106, 'M2'],\n",
       " [193, 195, 'M2'],\n",
       " [221, 225, 'M2'],\n",
       " [315, 316, 'N_CHAMBRES'],\n",
       " [343, 347, 'M2'],\n",
       " [363, 369, 'EXTERIEUR'],\n",
       " [434, 442, 'DEPOT_GARANTIE'],\n",
       " [473, 481, 'HONORAIRE'],\n",
       " [505, 509, 'LOYER_HC'],\n",
       " [536, 538, 'CHARGES_LOCATAIRE_MOIS'],\n",
       " [586, 590, 'HONORAIRE'],\n",
       " [602, 605, 'HONORAIRE']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ_labels([[0, 2, 'ADRESSE'],\n",
    " [3, 6, 'ADRESSE'],\n",
    " [7, 9, 'ADRESSE'],\n",
    " [10, 19, 'ADRESSE'],\n",
    " [28, 39, 'COPROPRIETE'],\n",
    " [43, 47, 'ANNEE_CONSTRUCTION'],\n",
    " [64, 69, 'N_ETAGE'],\n",
    " [92, 93, 'N_PIECES'],\n",
    " [104, 106, 'M2'],\n",
    " [193, 195, 'M2'],\n",
    " [221, 225, 'M2'],\n",
    " [315, 316, 'N_CHAMBRES'],\n",
    " [343, 347, 'M2'],\n",
    " [363, 369, 'EXTERIEUR'],\n",
    " [434, 442, 'DEPOT_GARANTIE'],\n",
    " [473, 481, 'HONORAIRE'],\n",
    " [505, 509, 'LOYER_HC'],\n",
    " [536, 538, 'CHARGES_LOCATAIRE_MOIS'],\n",
    " [586, 590, 'HONORAIRE'],\n",
    " [602, 605, 'HONORAIRE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui permet d'écrire un fichier json à partir du dataframe de l'annonce, des predictions établies \n",
    "#et des positions des mots\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "def pred_to_json(df, y_pred, pos):\n",
    "    #Format json\n",
    "    labels = list()\n",
    "    for l in range(len(y_pred[0])):\n",
    "        if (y_pred[0][l] != 'O'):\n",
    "            labels.append([pos.iloc[l][0],pos.iloc[l][1],y_pred[0][l][2:]])\n",
    "    \n",
    "    #On elimine les occurences de labels qui se suive\n",
    "    labels = occ_labels(labels)\n",
    "    ad = {\n",
    "        \"id\" : 1,\n",
    "        \"text\" : TreebankWordDetokenizer().detokenize(df['Words']), #detokenization ? des mots.. pas top top\n",
    "        \"meta\" : {},\n",
    "        \"annotation_approver\" : \"gabrielle\",\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "    \n",
    "    with open(\"test.json\",\"w\") as f:\n",
    "        json.dump(ad,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[df['Ad#']==482,:]\n",
    "X_crf_test=list() \n",
    "X_crf_test.append(ad2features(test))\n",
    "y_pred = crf.predict(X_crf_test)\n",
    "pred_to_json(test,y_pred,test['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ad#                                   482\n",
       "Words                            1.620,00\n",
       "Pos                            [434, 442]\n",
       "Tag                      B-DEPOT_GARANTIE\n",
       "is_small_word                           0\n",
       "is_number                               1\n",
       "is_first_letter_upper                   0\n",
       "is_all_upper                            0\n",
       "symbole_in_word                         1\n",
       "is_number_and_letter                    0\n",
       "is_key_word                             0\n",
       "2prev_word                             de\n",
       "2prev_key                               0\n",
       "prev_word                        garantie\n",
       "prev_key                                0\n",
       "next_word                           euros\n",
       "next_key                                1\n",
       "2next_word                              .\n",
       "2next_key                               0\n",
       "Name: 41144, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui prend en argument un dataframe contenant l'annonce et ses features et le type de modele à utiliser pour les\n",
    "#predictions et qui renvoie un fichier json\n",
    "\n",
    "def df_to_json(df,modele):\n",
    "    #Ecriture du dataframe au format dictionnaire\n",
    "    X_crf_test=list() \n",
    "    X_crf_test.append(ad2features(df))\n",
    "    y_pred = modele.predict(X_crf_test)\n",
    "    pred_to_json(df,y_pred,df['Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_json(test,crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui prend en argument un vecteur de mots, le modele etudié et la position des mots et qui ecrit un fichier json\n",
    "\n",
    "def vect_word_to_json(Vect_ad_word, position, modele):\n",
    "    #Mise au bon format du dataframe\n",
    "    data={'Words':Vect_ad_word,'Pos':position}\n",
    "    df=pd.DataFrame(data)\n",
    "    df[\"is_small_word\"]=is_small_word(df['Words'])\n",
    "    df[\"is_number\"]=is_number(df['Words'])\n",
    "    df[\"is_first_letter_upper\"]=is_first_letter_upper(df['Words'])\n",
    "    df[\"is_all_upper\"]=is_all_upper(df['Words'])\n",
    "    df[\"symbole_in_word\"]=symbole_in_word(df['Words'])\n",
    "    df[\"is_number_and_letter\"]=is_number_and_letter(df['Words'])\n",
    "    df[\"is_key_word\"]=is_key_word(df['Words'])\n",
    "    \n",
    "    list_prev_word=list()\n",
    "    list_2prev_word=list()\n",
    "    list_next_word=list()\n",
    "    list_2next_word=list()\n",
    "\n",
    "    list_prev_key=list()\n",
    "    list_2prev_key=list()\n",
    "    list_next_key=list()\n",
    "    list_2next_key=list()\n",
    "    Vect_ad_key=df[\"is_key_word\"]\n",
    "    \n",
    "    for j in range(len(Vect_ad_word)):\n",
    "        # Pour chaque annonce, on fait attention aux deux premiers et deux derniers mots  \n",
    "        if j==0:\n",
    "            list_prev_word.append(\"__Start1__\")\n",
    "            list_2prev_word.append(\"__Start2__\")\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(0)\n",
    "            list_2prev_key.append(0)\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])\n",
    "            \n",
    "        elif j==1:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(\"__Start1__\")\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(0)\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])\n",
    "        \n",
    "        elif j==len(Vect_ad_word)-2:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(\"__End1__\")\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(0)\n",
    "        \n",
    "        elif j==len(Vect_ad_word)-1:\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(\"__End1__\")\n",
    "            list_2next_word.append(\"__End2__\")\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(0)\n",
    "            list_2next_key.append(0)\n",
    "        else :\n",
    "            list_prev_word.append(Vect_ad_word.iloc[j-1])\n",
    "            list_2prev_word.append(Vect_ad_word.iloc[j-2])\n",
    "            list_next_word.append(Vect_ad_word.iloc[j+1])\n",
    "            list_2next_word.append(Vect_ad_word.iloc[j+2])\n",
    "            \n",
    "            list_prev_key.append(Vect_ad_key.iloc[j-1])\n",
    "            list_2prev_key.append(Vect_ad_key.iloc[j-2])\n",
    "            list_next_key.append(Vect_ad_key.iloc[j+1])\n",
    "            list_2next_key.append(Vect_ad_key.iloc[j+2])\n",
    "    \n",
    "    df[\"2prev_word\"]=list_2prev_word\n",
    "    df[\"2prev_key\"]=list_2prev_key\n",
    "\n",
    "    df[\"prev_word\"]=list_prev_word\n",
    "    df[\"prev_key\"]=list_prev_key\n",
    "\n",
    "    df[\"next_word\"]=list_next_word\n",
    "    df[\"next_key\"]=list_next_key\n",
    "\n",
    "    df[\"2next_word\"]=list_2next_word\n",
    "    df[\"2next_key\"]=list_2next_key\n",
    "    \n",
    "    df_to_json(df,modele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_word_to_json(test['Words'], test['Pos'], crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
